{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a36abc9-47b6-4e9a-8d2c-330e64012db2",
   "metadata": {},
   "source": [
    "# 迁移学习微调训练图像分类模型\n",
    "\n",
    "在自己的图像分类数据集上，使用ImageNet预训练图像分类模型初始化，改动分类层，迁移学习微调训练\n",
    "\n",
    "同济子豪兄：https://space.bilibili.com/1900783\n",
    "\n",
    "[代码运行云GPU环境](https://featurize.cn/?s=d7ce99f842414bfcaea5662a97581bd1)：GPU RTX 3060、CUDA v11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d59cc6-c7c9-46d6-a5d2-d5da1d7ed4bc",
   "metadata": {},
   "source": [
    "## 设置matplotlib中文字体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c7ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981d43b0-08f2-4c00-973c-071a7c7205e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # windows操作系统\n",
    "plt.rcParams['font.sans-serif']=['SimHei']  # 用来正常显示中文标签 \n",
    "plt.rcParams['axes.unicode_minus']=False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9065b0da-f63f-4915-bae1-7fd9c729af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac操作系统，参考 https://www.ngui.cc/51cto/show-727683.html\n",
    "# 下载 simhei.ttf 字体文件\n",
    "# !wget https://zihao-openmmlab.obs.cn-east-3.myhuaweicloud.com/20220716-mmclassification/dataset/SimHei.ttf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c680af5c-d54b-45d2-90f8-04554da4d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux操作系统，例如 云GPU平台：https://featurize.cn/?s=d7ce99f842414bfcaea5662a97581bd1\n",
    "# 如果遇到 SSL 相关报错，重新运行本代码块即可\n",
    "# !wget https://zihao-openmmlab.obs.cn-east-3.myhuaweicloud.com/20220716-mmclassification/dataset/SimHei.ttf -O /environment/miniconda3/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/SimHei.ttf\n",
    "# !rm -rf /home/featurize/.cache/matplotlib\n",
    "# \n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# matplotlib.rc(\"font\",family='SimHei') # 中文字体\n",
    "# plt.rcParams['axes.unicode_minus']=False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c174f-33c0-44fa-af53-14237d35b37d",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b35d923-b9e9-4ea4-914a-5bf05b93a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 忽略烦人的红色提示\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d48dc-580c-4c07-8d4e-02f99634c952",
   "metadata": {},
   "source": [
    "## 获取计算硬件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e14f47aa-9ccb-4d56-a100-a5a82a97a43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 有 GPU 就用 GPU，没有就用 CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9499c1-0594-48b8-80f0-e7fdbc30dbe3",
   "metadata": {},
   "source": [
    "## 图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81f0ca03-de86-450d-a47e-6f0e7c19d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 训练集图像预处理：缩放裁剪、图像增强、转 Tensor、归一化\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "# 测试集图像预处理-RCTN：缩放、裁剪、转 Tensor、归一化\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d059c79-5b67-49fe-9baa-1bcd363208dc",
   "metadata": {},
   "source": [
    "## 载入图像分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf6544a-6af5-4b07-93df-d863157b9290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集文件夹路径\n",
    "dataset_dir = os.path.join(os.path.abspath('.'), 'data', 'fruit30_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccb23900-b48f-4839-9cf5-82c9d07b42a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集路径 E:\\HarmonyosDev\\projects\\ImageRecognition\\server\\notebooks\\data\\fruit30_split\\train\n",
      "测试集路径 E:\\HarmonyosDev\\projects\\ImageRecognition\\server\\notebooks\\data\\fruit30_split\\val\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dataset_dir, 'train')\n",
    "test_path = os.path.join(dataset_dir, 'val')\n",
    "print('训练集路径', train_path)\n",
    "print('测试集路径', test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eb2572f-3823-430e-81d5-ef202fa52244",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'data\\\\fruit30_split\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 载入训练集\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 载入测试集\u001b[39;00m\n\u001b[0;32m      8\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(test_path, test_transform)\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\deep2Learning\\lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\deep2Learning\\lib\\site-packages\\torchvision\\datasets\\folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 144\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\deep2Learning\\lib\\site-packages\\torchvision\\datasets\\folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    192\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\deep2Learning\\lib\\site-packages\\torchvision\\datasets\\folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'data\\\\fruit30_split\\\\train'"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "# 载入训练集\n",
    "train_dataset = datasets.ImageFolder(train_path, train_transform)\n",
    "\n",
    "# 载入测试集\n",
    "test_dataset = datasets.ImageFolder(test_path, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df766b1f-a51f-4c3f-a916-08fc633713a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('训练集图像数量', len(train_dataset))\n",
    "print('类别个数', len(train_dataset.classes))\n",
    "print('各类别名称', train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa33a8d8-2e9e-43d9-bcfd-09f0c9d6619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('测试集图像数量', len(test_dataset))\n",
    "print('类别个数', len(test_dataset.classes))\n",
    "print('各类别名称', test_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e98be-4648-4d34-9e6c-273a55127b4d",
   "metadata": {},
   "source": [
    "## 类别和索引号 一一对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f737200-3afd-46f7-9c42-52c66829572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各类别名称\n",
    "class_names = train_dataset.classes\n",
    "n_class = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f0a680-7511-46a9-b3a3-2c8fc20d9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671913e-b8f5-4410-bf12-2e942d9d4e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射关系：类别 到 索引号\n",
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ab397-19fa-404e-aaa0-20dfadc02bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射关系：索引号 到 类别\n",
    "idx_to_labels = {y:x for x,y in train_dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ce6c26-65a2-4f49-b877-064479365487",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74e138-c9bb-48f4-aed6-c5e4b4ce2b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存为本地的 npy 文件\n",
    "np.save('idx_to_labels.npy', idx_to_labels)\n",
    "np.save('labels_to_idx.npy', train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d3824-e6bb-4f50-9802-f073d9151311",
   "metadata": {},
   "source": [
    "## 定义数据加载器DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300daf13-807a-4f80-a2cc-ee3675a64c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a787702d-61c6-41af-9cbd-19bc5d3baae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# 训练集的数据加载器\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4\n",
    "                         )\n",
    "\n",
    "# 测试集的数据加载器\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e837d-df50-4af8-a395-22e550b3d1f2",
   "metadata": {},
   "source": [
    "## 查看一个batch的图像和标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28879d37-687b-45a8-b980-731df68dab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 是 python生成器，每次调用返回一个 batch 的数据\n",
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8711c143-d26b-4c70-9da9-f1a78a89c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7305eb-e333-4325-9aa3-cc58c59a175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147df415-b72d-4556-a75f-adb57ddbff6a",
   "metadata": {},
   "source": [
    "## 可视化一个batch的图像和标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cee8f7-9f9a-441b-9e7f-cc3ebf2b534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集中的Tensor张量转为numpy的array数据类型\n",
    "images = images.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4013567-7a8e-40fc-9ce5-435a283cacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d7d5d-3028-4d60-b2ec-172762c36688",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(images[5].flatten(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713484b7-cc92-4fbe-9891-6a635fca54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 中经过预处理的图像\n",
    "idx = 2\n",
    "plt.imshow(images[idx].transpose((1,2,0))) # 转为(224, 224, 3)\n",
    "plt.title('label:'+str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488f9f7c-aba0-42a0-9520-3ba2533f9747",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = labels[idx].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1dd61-dd3a-4233-86ad-1d2f7cdd6f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe5e73-cc5c-4ebb-b24e-0a2c785d2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classname = idx_to_labels[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c0a93-c625-4f74-a8da-8b675e3d3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc3188-33a6-476f-928e-7abcf8f8db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始图像\n",
    "idx = 2\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "plt.imshow(np.clip(images[idx].transpose((1,2,0)) * std + mean, 0, 1))\n",
    "plt.title('label:'+ pred_classname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b52d04-a791-4feb-8b57-af98b253ebba",
   "metadata": {},
   "source": [
    "## 导入训练需使用的工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684da643-5a88-4ba2-b49c-5dc98b35100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c95e0a3-795b-4ceb-8d0c-11c452744909",
   "metadata": {},
   "source": [
    "## 选择迁移学习训练方式\n",
    "\n",
    "斯坦福CS231N【迁移学习】中文精讲：https://www.bilibili.com/video/BV1K7411W7So\n",
    "\n",
    "斯坦福CS231N【迁移学习】官方笔记：https://cs231n.github.io/transfer-learning\n",
    "\n",
    "ResNet算法精讲与论文逐句精读：https://www.bilibili.com/video/BV1vb4y1k7BV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f90378-350d-48c2-98f7-e4fb3151aeb6",
   "metadata": {},
   "source": [
    "### 选择一：只微调训练模型最后一层（全连接分类层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23269f1a-ea51-4321-a1c3-20e572f4f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True) # 载入预训练模型\n",
    "\n",
    "# 修改全连接层，使得全连接层的输出与当前数据集类别数对应\n",
    "# 新建的层默认 requires_grad=True\n",
    "model.fc = nn.Linear(model.fc.in_features, n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d39213-c7a0-456f-973d-b1fb070040d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9ae51-045f-4c33-9c1e-0e5b263eb0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只微调训练最后一层全连接层的参数，其它层冻结\n",
    "optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae51ee7-63fc-4895-ab0d-69815359032e",
   "metadata": {},
   "source": [
    "### 选择二：微调训练所有层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20cdc2b-3cd2-472b-bf63-2e34a3d39a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet18(pretrained=True) # 载入预训练模型\n",
    "\n",
    "# model.fc = nn.Linear(model.fc.in_features, n_class)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6da8b-ab76-4568-bf3a-09c4ec3434b7",
   "metadata": {},
   "source": [
    "### 选择三：随机初始化模型全部权重，从头训练所有层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c792cc4-ab64-403f-a7c9-80f3bee01c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet18(pretrained=False) # 只载入模型结构，不载入预训练权重参数\n",
    "\n",
    "# model.fc = nn.Linear(model.fc.in_features, n_class)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e92213d-d6d9-435f-a4c0-4bcdbdf7c6b8",
   "metadata": {},
   "source": [
    "## 训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5146eb0-f25e-400c-bbd6-e567f8aab8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# 交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# 训练轮次 Epoch\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d188eff-603c-475f-938a-ca10aa9427cc",
   "metadata": {},
   "source": [
    "## 模拟一个batch的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376d88f-127d-47a8-8367-2a3e4670fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得一个 batch 的数据和标注\n",
    "images, labels = next(iter(train_loader))\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4147f53-0de3-4757-b5d1-575f5ae3273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入模型，执行前向预测\n",
    "outputs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc18cf4-bdf0-43ff-9d82-4de67fe4ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得当前 batch 所有图像的预测类别 logit 分数\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566da53-8fd3-4f70-b33c-edc40f8ea8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由 logit，计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
    "loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e28997-4544-4cae-8e65-92995dd9e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反向传播“三部曲”\n",
    "optimizer.zero_grad() # 清除梯度\n",
    "loss.backward() # 反向传播\n",
    "optimizer.step() # 优化更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fabd3ba-d950-4ffa-a1af-9e4cb0dc8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得当前 batch 所有图像的预测类别\n",
    "_, preds = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac9a4f-a1be-447a-9429-17b5ef2c922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11de94-c0f6-47fb-9785-0aedb0fc9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733fec36-70de-4a8a-a985-57148fd36815",
   "metadata": {},
   "source": [
    "## 运行完整训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630791f-3137-49cd-8e38-3a788f84ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历每个 EPOCH\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for images, labels in train_loader:  # 获取训练集的一个 batch，包含数据和标注\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)           # 前向预测，获得当前 batch 的预测结果\n",
    "        loss = criterion(outputs, labels) # 比较预测结果和标注，计算当前 batch 的交叉熵损失函数\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()                   # 损失函数对神经网络权重反向传播求梯度\n",
    "        optimizer.step()                  # 优化更新神经网络权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf71013-075b-4878-884a-c5c650772f82",
   "metadata": {},
   "source": [
    "## 在测试集上初步测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18416eb-ee78-420a-b48a-95727c992c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(test_loader): # 获取测试集的一个 batch，包含数据和标注\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)              # 前向预测，获得当前 batch 的预测置信度\n",
    "        _, preds = torch.max(outputs, 1)     # 获得最大置信度对应的类别，作为预测结果\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum()   # 预测正确样本个数\n",
    "\n",
    "    print('测试集上的准确率为 {:.3f} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773da35f-3c61-4fbc-b00a-de7f612e3046",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201086a-a2ba-48bd-839d-f044b5419a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'checkpoint/fruit30_pytorch_C1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e39fa3-29c0-489a-854e-b4df1c1bcf57",
   "metadata": {},
   "source": [
    "## 参考文档\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "https://www.bilibili.com/video/BV1qe4y1D7zD\n",
    "\n",
    "https://www.bilibili.com/video/BV14J411X7Bb\n",
    "\n",
    "https://www.bilibili.com/video/BV1w4411u7ay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d2504-a78a-4145-8520-5206fb51b829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep2Learning",
   "language": "python",
   "name": "deep2learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
